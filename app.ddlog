#Some random changes

#*****  Schema for DeepDive-ready DB Dump:  ***********************
#
#    doc_id         text, 
#    sentence_index int,
#    sentence       text,
#    tokens         text[],
#    pos_tags       text[],
#    ner_tags       text[], 
#    lemmas         text[],
#    dep_types      text[],
#    dep_tokens     int[],
#    doc_offsets    text 
#
#*****  Schema for bazaar result:  ********************************
#
#
#        doc_id		text,
#	sentence_index	int,
#	sentence_text	text,
#	tokens		text[],
#	lemmas		text[],
#	pos_tags	text[],
#	ner_tags	text[],
#	doc_offsets	int[],
#	dep_types	text[],
#	dep_tokens	int[]



#***** Result table

res?(

    p1_id text,
    p2_id text
).

#***** Articles table
#    The "id" has the dois and the "content" is all the text from the article.

articles(
	id	text,
	content	text
).


#***** Sentences table with parsed text.   
sentences(
    doc_id         text, sentence_index int,
    tokens         json, lemmas         json,
    pos_tags       json, ner_tags       json,
    doc_offsets    json, dep_types      json,
    dep_tokens     json
).
sentences_tsv
(
    doc_id         text, sentence_index int,
    tokens_index   int[], tokens         text[],
    pos_tags       text[], ner_tags       text[], 
    lemmas         text[], dep_types      text[],
    dep_tokens     int[], doc_offsets    text[]
).

   
#deepdive sql 'INSERT INTO sentences (SELECT doc_id, sentence_index, to_json(tokens) AS tokens, to_json(lemmas) AS lemmas, to_json(pos_tags) AS pos_tags,to_json(ner_tags) AS ner_tags, to_json(doc_offsets) AS doc_offsets, to_json(dep_types) AS dep_types, to_json(dep_tokens) AS dep_tokens FROM sentences_tsv)'

#**** Bazaar's parser function
function nlp_markup over (
	 doc_id	    text,
	 content    text
	 ) returns rows like sentences
	 implementation "udf/nlp_markup.sh" handles tsj lines.
## CREATE SENTENCES ##
sentences+= nlp_markup(doc_id, content) :-
	  articles(doc_id, content).

##*** Tables to save enzymes and metabolites information (NOT USED)
#enzymes(EC text, name text, other_names text[], reaction text, comments text).
#metabolites(formula text, names text[]).
###########################################

# **** mention_enz is a table of enzyme mentions mapped from 
#    the sentences table using the map_enz
#    function. The extraction command is
#    the third part of this code.
mention_enz(
    mention_id text,
    mention_text text,
    doc_id text,
    sentence_index int,
    begin_index int,
    end_index int
).

function map_enz over (
        doc_id text,
        sentence_index int,
        tokens text[],
        pos_tags text[],
        ner_tags text[]
    ) returns rows like mention_enz
    implementation "udf/map_enz.py" handles tsj lines.

mention_enz += map_enz (
    doc_id, sentence_index, tokens, pos_tags,ner_tags
) :- sentences(doc_id, sentence_index, tokens, _, pos_tags, ner_tags, _, _, _).

mention_met( mention_id text,
             mention_text text,
             doc_id text, sentence_index int, begin_index int, end_index int ).

function map_mention_m over (
        doc_id text, 
        sentence_index int,
        tokens text[],
        pos_tags text[],
        ner_tags text[]
    ) returns rows like mention_met
    implementation "udf/map_mention_m.py" handles tsj lines.

mention_met += map_mention_m (
     doc_id, sentence_index, tokens, pos_tags,ner_tags
) :- sentences(doc_id, sentence_index, tokens, _, pos_tags, ner_tags, _, _, _).

mention_e(
    mention_id text,
    mention_text text,

    doc_id text,
    sentence_index int,
    begin_index int,
    end_index int
).

function map_mention_e over (
        doc_id text,
        sentence_index int,
        tokens text[],
        pos_tags text[],
        ner_tags text[]
    ) returns rows like mention_e
    implementation "udf/map_mention_ecoli.py" handles tsj lines.

mention_e += map_mention_e(
    doc_id, sentence_index, tokens, pos_tags,ner_tags
) :- sentences(doc_id, sentence_index, tokens, _, pos_tags, ner_tags, _, _, _).


# **** mention_w is a table of key words
#    to find promiscuous or novel function
#    mentions mapped from the sentences 
#    table using the map_words
#    function. The extraction command is
#    the third part of this code.

mention_w(
    mention_id text,
    mention_text text,
    doc_id text,
    sentence_index int,
    begin_index int,
    end_index int
).

function map_words over (
        doc_id text,
        sentence_index int,
        tokens text[],
        pos_tags text[],
        ner_tags text[]
    ) returns rows like mention_w
    implementation "udf/map_words.py" handles tsj lines.

mention_w += map_words(
    doc_id, sentence_index, tokens, pos_tags,ner_tags
) :- sentences(doc_id, sentence_index, tokens, _, pos_tags, ner_tags, _, _, _).

# Get distinct mentions
    
#num_mentions_m(doc_id, sentence_index, COUNT(m)) :- 
 #   mention_m(m, _, doc_id, sentence_index, _, _).
        
num_mentions_enz(doc_id, sentence_index, COUNT(m)) :- 
    mention_enz(m, _, doc_id, sentence_index, _, _).

## **** The candidates table contains the pairs of enzyme and key words
#    mentions that are in the same sentence.

candidates (
        p1_id text,
        p1_mention text,
        p2_id text,
        p2_mention text
).

candidates(p1_id, p1_mention, p2_id, p2_mention) :-
    mention_enz(p1_id, p1_mention, doc_id, sentence_index, p1_begin, _),
    mention_w(p2_id, p2_mention, doc_id, sentence_index, p2_begin, _).

candidates_enz_met (
        p1_id text,
        p1_mention text,
        p2_id text,
        p2_mention text
).

candidates_enz_met(p1_id, p1_mention, p2_id, p2_mention) :-
    mention_enz(p1_id, p1_mention, doc_id, sentence_index, p1_begin, _),
    mention_met(p2_id, p2_mention, doc_id, sentence_index, p2_begin, _),
    p1_begin != p2_begin.

candidates_enz_eco_w (
        p1_id text,
        p1_mention text,
        p2_id text,
        p2_mention text,
        p3_id text,
        p3_mention text
).

candidates_enz_eco_w(p1_id, p1_mention, p2_id, p2_mention, p3_id, p3_mention) :-
    mention_enz(p1_id, p1_mention, doc_id, sentence_index, p1_begin, _),
    mention_w(p2_id, p2_mention, doc_id, sentence_index, p2_begin, _),
    mention_e(p3_id, p3_mention, doc_id, sentence_index, p3_begin, _).

#  Commented rules. p2_mention is a word mapped form a small set of key words, 
#  it can't be equal to an enzyme mention (p1_mention). Both mentions are from 
#  different set of words.
#    p1_begin != p2_begin,   
#    p1_mention != p2_mention.

# **** Features extracted with the DeepDive feature extractor.
#    The features are extracted from the candidates.

feature(
    p1_id text,
    p2_id text,
    feature text
).

function extract_features over (
        p1_id text, 
        p2_id text, 
        p1_begin int, 
        p1_end int, 
        p2_begin int,  
        p2_end int,
        doc_id text, 
        sentence_index int,
        tokens text[],
        pos_tags text[],
        ner_tags text[],
        lemmas text[],
        dep_types text[],
        dep_tokens int[]
    ) returns rows like feature
    implementation "udf/extract_features.py" handles tsj lines.

feature += extract_features(
    p1_id, p2_id, p1_begin, p1_end, p2_begin, p2_end,
    doc_id, sentence_index, tokens, pos_tags, ner_tags, lemmas, dep_types, dep_tokens
) :-
    candidates(p1_id, _, p2_id, _ ),
    mention_enz(p1_id, _, doc_id, sentence_index, p1_begin, p1_end),
    mention_w(p2_id, _, doc_id, sentence_index, p2_begin, p2_end),
    sentences(doc_id, sentence_index, tokens, lemmas, pos_tags, ner_tags, _, dep_types, dep_tokens).


# **** The label table is were we store the positive
#    or negative points for each candidate.
#    The function supervise finds the constrains 
#    to give the points to the sentence, depending if 
#    they fit some condition.

label(
    p1_id text,
    p2_id text, 
    label int,
    rule_id text
).

label(p1_id,p2_id, 0, NULL) :- candidates( p1_id, _, p2_id, _).

function supervise over (
        p1_id text, 
        p2_id text, 
        p1_begin int, p1_end int, p2_begin int,  p2_end int,
        doc_id         text,
        sentence_index int,
        tokens         text[],
        pos_tags       text[],
        ner_tags       text[],
        lemmas         text[], 
        dep_types      text[],
        dep_tokens     int[]
    ) returns (
        p1_id text ,p2_id text, label int, rule_id text
    )
    implementation "udf/supervise.py" handles tsj lines.

label += supervise(
    p1_id, p2_id, p1_begin, p1_end, p2_begin,  p2_end,
    doc_id, sentence_index, tokens,  pos_tags, ner_tags,lemmas, dep_types, dep_token
) :- 
    candidates(p1_id, _, p2_id, _),
    mention_enz(p1_id, _, doc_id, sentence_index,p1_begin, p1_end),
    mention_w(p2_id, _, doc_id, sentence_index,p2_begin, p2_end),
    sentences(doc_id, sentence_index, tokens, lemmas, pos_tags, ner_tags, _, dep_types, dep_token).


# *** The table label_resolved has the sum of all the points
#    given by the supervise function.

label_resolved(p1_id, p2_id, SUM(vote)) :- label(p1_id, p2_id, vote, rule_id).


# assign the resolved labels for the relation

res(p1_id, p2_id) = if l > 0 then TRUE
                      else if l < 0 then FALSE
                      else NULL end :- label_resolved(p1_id, p2_id, l).



#res(p1_id, p2_id) = NULL :- candidates(p1_id, _, p2_id, _).


############################################################################
## Inference Rule ##########################################################
############################################################################

@weight(f)
res(p1_id, p2_id) :-
    candidates(p1_id, _, p2_id, _),
    feature(p1_id, p2_id, f).
#    label(p1_id, p2_id, l, _).    

#feature(p1_id,p2_id,f).




